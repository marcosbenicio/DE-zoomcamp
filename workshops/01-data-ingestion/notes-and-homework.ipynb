{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Outline**\n",
    "\n",
    "- [**1. Data Extraction with DLT (Data Load Tool)**](#1.-data-extraction-with-dlt-(data-load-tool))\n",
    "    - [1.1. Extracting API Data With a Generator](#1.1.-extracting-api-data-with-a-generator)\n",
    "    - [1.2. Extracting File Data With a Generator (Streaming)](#1.2.-extracting-file-data-with-a-generator-(streaming))\n",
    "    - [1.3  Extracting Data with dlt](#1.3-extracting-data-with-dlt)\n",
    "- [**2. Normalization**](#2.-normalization)\n",
    "- [**3. Incremental Loading**](#3.-incremental-loading)\n",
    "- [**5. Homework**](#5.-homework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import dlt\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Data Extraction with dlt (Data Load Tool)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extracting API Data With a Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a scenario where we want to retrieve data from an HTTP API that supports pagination. This API divides the data into pages, with each page containing up to 1000 records. If a request is made for a page number that exceeds the available data , the API returns an empty response, indicating that there are no more records to fetch.\n",
    "\n",
    "For this purpose, was created a simple API that returns paginated data with flask and google clound function. The API is available at the following URL:\n",
    "\n",
    "```bash\n",
    "    https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\n",
    "```\n",
    "\n",
    "To achieve this, we can use a python generator to allow fetch and process the data on a per-page basis without needing to load all data into memory at once. The generator function is a special type of iterator that generates values on the fly as they are requested rather than storing them all at once in memory. We can achieve efficient data retrieval that scales well and conserves memory.\n",
    "\n",
    "\n",
    "The following script is designed to iteratively request each page of data from the API until all pages have been retrieved, processing each page one by one, without loading the entire dataset into memory at once.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got page number 1 with 1000 records\n",
      "got page number 2 with 1000 records\n",
      "got page number 3 with 1000 records\n",
      "got page number 4 with 1000 records\n",
      "got page number 5 with 1000 records\n",
      "got page number 6 with 1000 records\n",
      "got page number 7 with 1000 records\n",
      "got page number 8 with 1000 records\n",
      "got page number 9 with 1000 records\n",
      "got page number 10 with 1000 records\n",
      "got page number 11 with 0 records\n",
      "Data written to .jsonl file\n"
     ]
    }
   ],
   "source": [
    "BASE_API_URL = \"https://us-central1-dlthub-analytics.cloudfunctions.net/data_engineering_zoomcamp_api\"\n",
    "\n",
    "\n",
    "def paginated_getter():\n",
    "    ''' \n",
    "        This function handles pagination by requesting one page of data at a time,\n",
    "        yielding the results to allow for processing in smaller, manageable \"microbatches.\"\n",
    "    '''\n",
    "    page_number = 1\n",
    "\n",
    "    while True:\n",
    "        # Set the query parameters\n",
    "        params = {'page': page_number}\n",
    "\n",
    "        # Make the GET request to the API\n",
    "        response = requests.get(BASE_API_URL, params=params)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "        page_json = response.json()\n",
    "        print(f'got page number {page_number} with {len(page_json)} records')\n",
    "\n",
    "        # if the page has no records, stop iterating\n",
    "        if not page_json:\n",
    "            break # No more data, break the loop\n",
    "        else:\n",
    "            yield page_json\n",
    "            page_number += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Open the file once and write as we fetch each page\n",
    "    with open('nyc_taxi_trip.jsonl', 'w') as file:\n",
    "        for page_data in paginated_getter():\n",
    "            for record in page_data:\n",
    "                json.dump(record, file)\n",
    "                file.write('\\n')  # New line for next record\n",
    "    print(\"Data written to .jsonl file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a JSON lines file to store the data. The JSON is not efficient for large datasets because the entire file must be read into memory to parse the JSON structure, potentially leading to high memory usage. On the other hand, the JSON lines format has each line treated as a separate JSON object,  This allows for reading and writing in chunks and is more memory-efficient for large datasets.\n",
    "\n",
    "This script is useful when we need to process or analyze data on the fly, page by page, especially when dealing with large datasets that wouldn't fit into memory. We can now check the data by using the `pandas.read_json` function with the `lines=True` parameter to efficiently read the JSON Lines file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Payment_Type</th>\n",
       "      <th>Rate_Code</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Tolls_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Trip_Dropoff_DateTime</th>\n",
       "      <th>Trip_Pickup_DateTime</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>store_and_forward</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>vendor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.742963</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2009-06-14 23:48:00</td>\n",
       "      <td>2009-06-14 23:23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.740187</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2009-06-18 17:43:00</td>\n",
       "      <td>2009-06-18 17:35:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.718043</td>\n",
       "      <td>-74.004745</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.761945</td>\n",
       "      <td>-73.983038</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2009-06-10 18:27:00</td>\n",
       "      <td>2009-06-10 18:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.739637</td>\n",
       "      <td>-73.985233</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.749802</td>\n",
       "      <td>-73.992247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2009-06-14 23:58:00</td>\n",
       "      <td>2009-06-14 23:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.730032</td>\n",
       "      <td>-73.852693</td>\n",
       "      <td>25.7</td>\n",
       "      <td>1</td>\n",
       "      <td>CASH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.776825</td>\n",
       "      <td>-73.949233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.85</td>\n",
       "      <td>11.09</td>\n",
       "      <td>2009-06-13 13:23:00</td>\n",
       "      <td>2009-06-13 13:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     End_Lat    End_Lon  Fare_Amt  Passenger_Count Payment_Type  Rate_Code  \\\n",
       "0  40.742963 -73.980072      45.0                1       Credit        NaN   \n",
       "1  40.740187 -74.005698       6.5                1       Credit        NaN   \n",
       "2  40.718043 -74.004745      12.5                5       Credit        NaN   \n",
       "3  40.739637 -73.985233       4.9                1         CASH        NaN   \n",
       "4  40.730032 -73.852693      25.7                1         CASH        NaN   \n",
       "\n",
       "   Start_Lat  Start_Lon  Tip_Amt  Tolls_Amt  Total_Amt  Trip_Distance  \\\n",
       "0  40.641525 -73.787442      9.0       4.15      58.15          17.52   \n",
       "1  40.722065 -74.009767      1.0       0.00       8.50           1.56   \n",
       "2  40.761945 -73.983038      2.0       0.00      15.50           3.37   \n",
       "3  40.749802 -73.992247      0.0       0.00       5.40           1.11   \n",
       "4  40.776825 -73.949233      0.0       4.15      29.85          11.09   \n",
       "\n",
       "  Trip_Dropoff_DateTime Trip_Pickup_DateTime  mta_tax  store_and_forward  \\\n",
       "0   2009-06-14 23:48:00  2009-06-14 23:23:00      NaN                NaN   \n",
       "1   2009-06-18 17:43:00  2009-06-18 17:35:00      NaN                NaN   \n",
       "2   2009-06-10 18:27:00  2009-06-10 18:08:00      NaN                NaN   \n",
       "3   2009-06-14 23:58:00  2009-06-14 23:54:00      NaN                NaN   \n",
       "4   2009-06-13 13:23:00  2009-06-13 13:01:00      NaN                NaN   \n",
       "\n",
       "   surcharge vendor_name  \n",
       "0        0.0         VTS  \n",
       "1        1.0         VTS  \n",
       "2        1.0         VTS  \n",
       "3        0.5         VTS  \n",
       "4        0.0         VTS  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = 'nyc_taxi_trip.jsonl'\n",
    "chunk_size = 1000\n",
    "# Read the .jsonl file in chunks\n",
    "chunks = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunks:\n",
    "    # can perform operations on each chunk if necessary\n",
    "    display(chunk.head())\n",
    "    # Break after first chunk for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By processing each chunk individually, is possible to perform operations on each part of the dataset sequentially without needing to load the entire dataset into memory. This approach allows transform and analyze large datasets as a whole, chunk by chunk, and then concatenate these transformed chunks into a final dataset to export to a file or database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Extracting File Data With a Generator (Streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of JSONL files, where each line is a distinct JSON document (representing a data \"row\"), the streaming approach is straightforward. The process involves downloading and yielding each line one at a time. This method allows for immediate processing of each \"row\" as it arrives, optimizing both the speed of data handling and memory usage. \n",
    "\n",
    "- Pros:\n",
    "\n",
    "    - Streaming allows data to be processed as it's being downloaded, facilitating faster data handling without waiting for the entire download to complete.\n",
    "    \n",
    "    - Easy Memory Management: Since data is processed in chunks (line by line in the case of JSONL as did before), memory usage is minimized. This approach avoids loading the entire dataset into memory, which is particularly beneficial for large files.\n",
    "\n",
    "- Cons:\n",
    "\n",
    "    - Complexity with Columnar Formats: For formats like Parquet or ORC, which are organized by columns rather than rows, streaming can be challenging. These formats require downloading entire blocks of data to deserialize them into rows, complicating the streaming process.\n",
    "    \n",
    "    - Potential Code Complexity: Depending on the data format and the specific requirements of the data handling process, the code for streaming downloads can become complex, requiring careful management of the data stream and error handling.\n",
    "\n",
    "Consider a scenario where we want to retrieve a large file from a remote server and process it line by line. To do so, we can use a generator to stream the file's contents and process each line individually as in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>Trip_Pickup_DateTime</th>\n",
       "      <th>Trip_Dropoff_DateTime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Rate_Code</th>\n",
       "      <th>store_and_forward</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Payment_Type</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Tolls_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 23:23:00</td>\n",
       "      <td>2009-06-14 23:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-18 17:35:00</td>\n",
       "      <td>2009-06-18 17:43:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>40.740187</td>\n",
       "      <td>Credit</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-10 18:08:00</td>\n",
       "      <td>2009-06-10 18:27:00</td>\n",
       "      <td>5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>-73.983038</td>\n",
       "      <td>40.761945</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-74.004745</td>\n",
       "      <td>40.718043</td>\n",
       "      <td>Credit</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 23:54:00</td>\n",
       "      <td>2009-06-14 23:58:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-73.992247</td>\n",
       "      <td>40.749802</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.985233</td>\n",
       "      <td>40.739637</td>\n",
       "      <td>CASH</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-13 13:01:00</td>\n",
       "      <td>2009-06-13 13:23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11.09</td>\n",
       "      <td>-73.949233</td>\n",
       "      <td>40.776825</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.852693</td>\n",
       "      <td>40.730032</td>\n",
       "      <td>CASH</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_name Trip_Pickup_DateTime Trip_Dropoff_DateTime  Passenger_Count  \\\n",
       "0         VTS  2009-06-14 23:23:00   2009-06-14 23:48:00                1   \n",
       "1         VTS  2009-06-18 17:35:00   2009-06-18 17:43:00                1   \n",
       "2         VTS  2009-06-10 18:08:00   2009-06-10 18:27:00                5   \n",
       "3         VTS  2009-06-14 23:54:00   2009-06-14 23:58:00                1   \n",
       "4         VTS  2009-06-13 13:01:00   2009-06-13 13:23:00                1   \n",
       "\n",
       "   Trip_Distance  Start_Lon  Start_Lat Rate_Code store_and_forward    End_Lon  \\\n",
       "0          17.52 -73.787442  40.641525      None              None -73.980072   \n",
       "1           1.56 -74.009767  40.722065      None              None -74.005698   \n",
       "2           3.37 -73.983038  40.761945      None              None -74.004745   \n",
       "3           1.11 -73.992247  40.749802      None              None -73.985233   \n",
       "4          11.09 -73.949233  40.776825      None              None -73.852693   \n",
       "\n",
       "     End_Lat Payment_Type  Fare_Amt  surcharge mta_tax  Tip_Amt  Tolls_Amt  \\\n",
       "0  40.742963       Credit      45.0        0.0    None      9.0       4.15   \n",
       "1  40.740187       Credit       6.5        1.0    None      1.0       0.00   \n",
       "2  40.718043       Credit      12.5        1.0    None      2.0       0.00   \n",
       "3  40.739637         CASH       4.9        0.5    None      0.0       0.00   \n",
       "4  40.730032         CASH      25.7        0.0    None      0.0       4.15   \n",
       "\n",
       "   Total_Amt  \n",
       "0      58.15  \n",
       "1       8.50  \n",
       "2      15.50  \n",
       "3       5.40  \n",
       "4      29.85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total time: 0.3186216354370117\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://storage.googleapis.com/dtc_zoomcamp_api/yellow_tripdata_2009-06.jsonl\"\n",
    "\n",
    "def stream_download_jsonl(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            yield json.loads(line)\n",
    "\n",
    "# time the download\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Use the generator to iterate over rows with minimal memory usage\n",
    "max_preview_rows = 5\n",
    "row_counter = 0\n",
    "df_preview = pd.DataFrame() # Initialize empty DataFrame\n",
    "for row in stream_download_jsonl(url):\n",
    "    # Convert the row (dict) into a DataFrame and append it to the df_preview\n",
    "    df_preview = pd.concat([df_preview, pd.DataFrame([row])], ignore_index=True)\n",
    "    row_counter += 1\n",
    "    if row_counter >= max_preview_rows:\n",
    "        break\n",
    "\n",
    "display(df_preview)\n",
    "\n",
    "end = time.time()\n",
    "print('\\n Total time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Extracting Data with dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore a practical approach to downloading and inspecting data using the dlt library. The dlt library allows for the incremental processing of data from various sources, including generators, with a focus on optimizing memory usage.\n",
    "\n",
    "The dlt library enables us to load data into a database in an incremental manner. This approach is particularly useful when working with large datasets, as it helps manage memory efficiently by processing data in small, manageable chunks.\n",
    "\n",
    "we utilize DuckDB as the destination for our data. DuckDB is a lightweight, easy-to-use database optimized for analytical queries. Unlike databases such as PostgreSQL, DuckDB is designed to be used within an application. The entire database can be stored in a single file, making it very easy to distribute and deploy. This database performs computations in-memory, which can significantly speed up analytical queries and also efficiently manages memory to handle datasets larger than RAM.\n",
    "\n",
    "\n",
    "To install dlt with all the necessary DuckDB dependencies:\n",
    "\n",
    "```bash\n",
    "    pip install \"dlt[duckdb]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got page number 1 with 1000 records\n",
      "got page number 2 with 1000 records\n",
      "got page number 3 with 1000 records\n",
      "got page number 4 with 1000 records\n",
      "got page number 5 with 1000 records\n",
      "got page number 6 with 1000 records\n",
      "got page number 7 with 1000 records\n",
      "got page number 8 with 1000 records\n",
      "got page number 9 with 1000 records\n",
      "got page number 10 with 1000 records\n",
      "got page number 11 with 0 records\n",
      "Pipeline dlt_ipykernel_launcher load step completed in 2.35 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset generators\n",
      "The duckdb destination used duckdb:////home/marcos/GitHub/DE-zoomcamp/workshops/01-data-Ingestion/dlt_ipykernel_launcher.duckdb location to store data\n",
      "Load package 1708189774.5354438 is LOADED and contains no failed jobs\n",
      "Pipeline dlt_ipykernel_launcher load step completed in 2.25 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset generators\n",
      "The duckdb destination used duckdb:////home/marcos/GitHub/DE-zoomcamp/workshops/01-data-Ingestion/dlt_ipykernel_launcher.duckdb location to store data\n",
      "Load package 1708189800.5849261 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# define the connection to load to.\n",
    "# We could switch to Bigquery later\n",
    "generators_pipeline = dlt.pipeline(destination='duckdb', dataset_name='generators')\n",
    "\n",
    "\n",
    "# Load any generator to a table at the pipeline destination \n",
    "info = generators_pipeline.run(\tpaginated_getter(),\n",
    "\t\t\t\t\t\t\t\ttable_name=\"http_download\",\n",
    "\t\t\t\t\t\t\t\twrite_disposition=\"replace\" )\n",
    "\n",
    "# the outcome metadata is returned by the load\n",
    "print(info)\n",
    "\n",
    "# Load the next generator to the same or to a different table.\n",
    "info = generators_pipeline.run(\tstream_download_jsonl(url),\n",
    "\t\t\t\t\t\t\t\ttable_name=\"stream_download\",\n",
    "\t\t\t\t\t\t\t\twrite_disposition=\"replace\" )\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use SQL queries to access and analyze the data stored within the `.duckdb` file. To access data from the DuckDB file in a Python environment or Jupyter notebook, you would typically do the following:\n",
    "\n",
    "1. Connect to the DuckDB database file.\n",
    "2. Execute SQL queries using the connection.\n",
    "3. Fetch the results for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ http_download       │\n",
       "│ stream_download     │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " http_download table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>fare_amt</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>tip_amt</th>\n",
       "      <th>tolls_amt</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_dropoff_date_time</th>\n",
       "      <th>trip_pickup_date_time</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>store_and_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.742963</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>17.52</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1708189774.5354438</td>\n",
       "      <td>HOKtpMrIdmmW9w</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.740187</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Credit</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2009-06-18 14:43:00-03:00</td>\n",
       "      <td>2009-06-18 14:35:00-03:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VTS</td>\n",
       "      <td>1708189774.5354438</td>\n",
       "      <td>QZ47IFhLVf9XPg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     end_lat    end_lon  fare_amt  passenger_count payment_type  start_lat  \\\n",
       "0  40.742963 -73.980072      45.0                1       Credit  40.641525   \n",
       "1  40.740187 -74.005698       6.5                1       Credit  40.722065   \n",
       "\n",
       "   start_lon  tip_amt  tolls_amt  total_amt  trip_distance  \\\n",
       "0 -73.787442      9.0       4.15      58.15          17.52   \n",
       "1 -74.009767      1.0       0.00       8.50           1.56   \n",
       "\n",
       "     trip_dropoff_date_time     trip_pickup_date_time  surcharge vendor_name  \\\n",
       "0 2009-06-14 20:48:00-03:00 2009-06-14 20:23:00-03:00        0.0         VTS   \n",
       "1 2009-06-18 14:43:00-03:00 2009-06-18 14:35:00-03:00        1.0         VTS   \n",
       "\n",
       "         _dlt_load_id         _dlt_id  store_and_forward  \n",
       "0  1708189774.5354438  HOKtpMrIdmmW9w                NaN  \n",
       "1  1708189774.5354438  QZ47IFhLVf9XPg                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " stream_download table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>trip_pickup_date_time</th>\n",
       "      <th>trip_dropoff_date_time</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amt</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>tip_amt</th>\n",
       "      <th>tolls_amt</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>store_and_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>58.15</td>\n",
       "      <td>1708189800.5849261</td>\n",
       "      <td>h66odFRFv2I9QQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-18 14:35:00-03:00</td>\n",
       "      <td>2009-06-18 14:43:00-03:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>-74.009767</td>\n",
       "      <td>40.722065</td>\n",
       "      <td>-74.005698</td>\n",
       "      <td>40.740187</td>\n",
       "      <td>Credit</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1708189800.5849261</td>\n",
       "      <td>J/FOkhdWoT7sEQ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_name     trip_pickup_date_time    trip_dropoff_date_time  \\\n",
       "0         VTS 2009-06-14 20:23:00-03:00 2009-06-14 20:48:00-03:00   \n",
       "1         VTS 2009-06-18 14:35:00-03:00 2009-06-18 14:43:00-03:00   \n",
       "\n",
       "   passenger_count  trip_distance  start_lon  start_lat    end_lon    end_lat  \\\n",
       "0                1          17.52 -73.787442  40.641525 -73.980072  40.742963   \n",
       "1                1           1.56 -74.009767  40.722065 -74.005698  40.740187   \n",
       "\n",
       "  payment_type  fare_amt  surcharge  tip_amt  tolls_amt  total_amt  \\\n",
       "0       Credit      45.0        0.0      9.0       4.15      58.15   \n",
       "1       Credit       6.5        1.0      1.0       0.00       8.50   \n",
       "\n",
       "         _dlt_load_id         _dlt_id  store_and_forward  \n",
       "0  1708189800.5849261  h66odFRFv2I9QQ                NaN  \n",
       "1  1708189800.5849261  J/FOkhdWoT7sEQ                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Connect to the DuckDB\n",
    "conn = duckdb.connect(f\"{generators_pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# 2. Execute SQL queries\n",
    "    # Set the search path to the dataset name for easy access to the tables.\n",
    "conn.sql(f\"SET search_path = '{generators_pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"SHOW TABLES\"))\n",
    "\n",
    "print(\"\\n\\n\\n http_download table:\")\n",
    "# 3. Fetch the results for analysis\n",
    "    # Query the table and fetch the results into a Pandas DataFrame.\n",
    "rides = conn.sql(\"SELECT * FROM http_download\").df()\n",
    "display(rides.head(2))\n",
    "\n",
    "print(\"\\n\\n\\n stream_download table:\")\n",
    "passengers = conn.sql(\"SELECT * FROM stream_download\").df()\n",
    "display(passengers.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested data is organized in a hierarchical structure, where some elements contain other elements within themselves. When dealing with nested data, especially in formats like JSON, transforming it into a tabular format for databases can be difficult due to the hierarchical nature of the data. This structure is common in formats like JSON or XML, where data can be deeply nested. Example of a nested data:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"orderID\": 12345,\n",
    "  \"customer\": \"John Doe\",\n",
    "  \"items\": [\n",
    "    {\"productID\": 987, \"name\": \"Widget\", \"quantity\": 2},\n",
    "    {\"productID\": 654, \"name\": \"Gadget\", \"quantity\": 1}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "The `items` key holds an array of objects, each representing an item in the order. Each object within this array contains details about the item, such as its `productID`, `name`, and `quantity`. In other words, nested lists represent a `1:n` relationship, where each parent record might be associated with multiple child records. In such cases, it's more appropriate to represent these relationships using separate tables.\n",
    "\n",
    "Let's use dlt to normalize the nested data into a tabular format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline dlt_ipykernel_launcher load step completed in 0.49 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset taxi_rides\n",
      "The duckdb destination used duckdb:////home/marcos/GitHub/DE-zoomcamp/workshops/01-data-Ingestion/dlt_ipykernel_launcher.duckdb location to store data\n",
      "Load package 1708189805.4310012 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "nested_data = [\n",
    "    {\n",
    "        \"vendor_name\": \"VTS\",\n",
    "\t\t\t\t\"record_hash\": \"b00361a396177a9cb410ff61f20015ad\",\n",
    "        \"time\": {\n",
    "            \"pickup\": \"2009-06-14 23:23:00\",\n",
    "            \"dropoff\": \"2009-06-14 23:48:00\"\n",
    "        },\n",
    "        \"Trip_Distance\": 17.52,\n",
    "        # nested dictionaries could be flattened\n",
    "        \"coordinates\": { # coordinates__start__lon\n",
    "            \"start\": {\n",
    "                \"lon\": -73.787442,\n",
    "                \"lat\": 40.641525\n",
    "            },\n",
    "            \"end\": {\n",
    "                \"lon\": -73.980072,\n",
    "                \"lat\": 40.742963\n",
    "            }\n",
    "        },\n",
    "        \"Rate_Code\": None,\n",
    "        \"store_and_forward\": None,\n",
    "        \"Payment\": {\n",
    "            \"type\": \"Credit\",\n",
    "            \"amt\": 20.5,\n",
    "            \"surcharge\": 0,\n",
    "            \"mta_tax\": None,\n",
    "            \"tip\": 9,\n",
    "            \"tolls\": 4.15,\n",
    "\t\t\t\"status\": \"booked\"\n",
    "        },\n",
    "        \"Passenger_Count\": 2,\n",
    "        # nested lists need to be expressed as separate tables\n",
    "        \"passengers\": [\n",
    "            {\"name\": \"John\", \"rating\": 4.9},\n",
    "            {\"name\": \"Jack\", \"rating\": 3.9}\n",
    "        ],\n",
    "        \"Stops\": [\n",
    "            {\"lon\": -73.6, \"lat\": 40.6},\n",
    "            {\"lon\": -73.5, \"lat\": 40.5}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# define the connection to load to.\n",
    "# We now use duckdb, but you can switch to Bigquery later\n",
    "pipeline = dlt.pipeline(destination='duckdb', dataset_name='taxi_rides')\n",
    "\n",
    "\n",
    "\n",
    "# run with merge write disposition.\n",
    "# This is so scaffolding is created for the next example,\n",
    "# where we look at merging data\n",
    "\n",
    "info = pipeline.run(    nested_data,\n",
    "                        table_name=\"rides\",\n",
    "                        write_disposition=\"merge\",\n",
    "                        primary_key=\"record_hash\"   )\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded into a database using the dlt library and normalized into a flat, tabular structure using SQL, the data can be easily queried and analyzed using standard SQL queries. \n",
    "\n",
    "- dlt library processes the nested JSON data and automatically normalizes it by flattening the nested structure and splitting sub-documents into separate tables.\n",
    "\n",
    "- During the normalization process, dlt generates unique identifiers (`_dlt_id`) for each record in the parent table and corresponding foreign keys (`_dlt_parent_id`) in the child tables. These generated keys enable us to re-establish the relationships between the parent and child data by joining the tables on these keys.\n",
    "\n",
    "- dlt library automatically converts data types from the JSON format to database-compatible types.  For example, timestamp strings in the JSON data are converted to actual timestamp data types in the database.\n",
    "\n",
    "TO achieve this, consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ rides               │\n",
       "│ rides__passengers   │\n",
       "│ rides__stops        │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"show tables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Rides table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_hash</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>time__pickup</th>\n",
       "      <th>time__dropoff</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>coordinates__start__lon</th>\n",
       "      <th>coordinates__start__lat</th>\n",
       "      <th>coordinates__end__lon</th>\n",
       "      <th>coordinates__end__lat</th>\n",
       "      <th>payment__type</th>\n",
       "      <th>payment__amt</th>\n",
       "      <th>payment__surcharge</th>\n",
       "      <th>payment__tip</th>\n",
       "      <th>payment__tolls</th>\n",
       "      <th>payment__status</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.15</td>\n",
       "      <td>booked</td>\n",
       "      <td>2</td>\n",
       "      <td>1708189805.4310012</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        record_hash vendor_name              time__pickup  \\\n",
       "0  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "\n",
       "              time__dropoff  trip_distance  coordinates__start__lon  \\\n",
       "0 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "\n",
       "   coordinates__start__lat  coordinates__end__lon  coordinates__end__lat  \\\n",
       "0                40.641525             -73.980072              40.742963   \n",
       "\n",
       "  payment__type  payment__amt  payment__surcharge  payment__tip  \\\n",
       "0        Credit          20.5                   0             9   \n",
       "\n",
       "   payment__tolls payment__status  passenger_count        _dlt_load_id  \\\n",
       "0            4.15          booked                2  1708189805.4310012   \n",
       "\n",
       "          _dlt_id  \n",
       "0  1nSAWAKECC0JEA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Passengers table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>_dlt_root_id</th>\n",
       "      <th>_dlt_parent_id</th>\n",
       "      <th>_dlt_list_idx</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>e/7/OvcnJD1uhA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>B/ndNQLSBGpj2g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  rating    _dlt_root_id  _dlt_parent_id  _dlt_list_idx         _dlt_id\n",
       "0  John     4.9  1nSAWAKECC0JEA  1nSAWAKECC0JEA              0  e/7/OvcnJD1uhA\n",
       "1  Jack     3.9  1nSAWAKECC0JEA  1nSAWAKECC0JEA              1  B/ndNQLSBGpj2g"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Stops table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>_dlt_root_id</th>\n",
       "      <th>_dlt_parent_id</th>\n",
       "      <th>_dlt_list_idx</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>YtrudpQY9gWPVw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>Q5R2dScCRMuxbg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lon   lat    _dlt_root_id  _dlt_parent_id  _dlt_list_idx         _dlt_id\n",
       "0 -73.6  40.6  1nSAWAKECC0JEA  1nSAWAKECC0JEA              0  YtrudpQY9gWPVw\n",
       "1 -73.5  40.5  1nSAWAKECC0JEA  1nSAWAKECC0JEA              1  Q5R2dScCRMuxbg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\n\\n Rides table:\")\n",
    "rides = conn.sql(\"SELECT * FROM rides\").df()\n",
    "display(rides)\n",
    "\n",
    "print(\"\\n\\n\\n Passengers table:\")\n",
    "passengers = conn.sql(\"SELECT * FROM rides__passengers\").df()\n",
    "display(passengers)\n",
    "\n",
    "print(\"\\n\\n\\n Stops table:\")\n",
    "stops = conn.sql(\"SELECT * FROM rides__stops\").df()\n",
    "display(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates new tables for each distinct element inside the list and a flattened table for elements in the dictionary.\n",
    "\n",
    "Let's do the following sql query:\n",
    "\n",
    "- Select all columns from the `rides`, `rides__passengers`, and `rides__stops`\n",
    "\n",
    "- Join the `rides` table with the `rides__passengers` and `rides__stops` tables using the `_dlt_id` from `rides` and matching it with the `_dlt_parent_id` in both `rides__passengers` and `rides__stops`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " joined table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_hash</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>time__pickup</th>\n",
       "      <th>time__dropoff</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>coordinates__start__lon</th>\n",
       "      <th>coordinates__start__lat</th>\n",
       "      <th>coordinates__end__lon</th>\n",
       "      <th>coordinates__end__lat</th>\n",
       "      <th>payment__type</th>\n",
       "      <th>...</th>\n",
       "      <th>_dlt_root_id</th>\n",
       "      <th>_dlt_parent_id</th>\n",
       "      <th>_dlt_list_idx</th>\n",
       "      <th>_dlt_id_2</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>_dlt_root_id_2</th>\n",
       "      <th>_dlt_parent_id_2</th>\n",
       "      <th>_dlt_list_idx_2</th>\n",
       "      <th>_dlt_id_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>...</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>B/ndNQLSBGpj2g</td>\n",
       "      <td>-73.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>Q5R2dScCRMuxbg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>...</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>e/7/OvcnJD1uhA</td>\n",
       "      <td>-73.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>Q5R2dScCRMuxbg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>...</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1</td>\n",
       "      <td>B/ndNQLSBGpj2g</td>\n",
       "      <td>-73.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>YtrudpQY9gWPVw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>...</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>e/7/OvcnJD1uhA</td>\n",
       "      <td>-73.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>1nSAWAKECC0JEA</td>\n",
       "      <td>0</td>\n",
       "      <td>YtrudpQY9gWPVw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        record_hash vendor_name              time__pickup  \\\n",
       "0  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "1  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "2  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "3  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "\n",
       "              time__dropoff  trip_distance  coordinates__start__lon  \\\n",
       "0 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "1 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "2 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "3 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "\n",
       "   coordinates__start__lat  coordinates__end__lon  coordinates__end__lat  \\\n",
       "0                40.641525             -73.980072              40.742963   \n",
       "1                40.641525             -73.980072              40.742963   \n",
       "2                40.641525             -73.980072              40.742963   \n",
       "3                40.641525             -73.980072              40.742963   \n",
       "\n",
       "  payment__type  ...    _dlt_root_id  _dlt_parent_id  _dlt_list_idx  \\\n",
       "0        Credit  ...  1nSAWAKECC0JEA  1nSAWAKECC0JEA              1   \n",
       "1        Credit  ...  1nSAWAKECC0JEA  1nSAWAKECC0JEA              0   \n",
       "2        Credit  ...  1nSAWAKECC0JEA  1nSAWAKECC0JEA              1   \n",
       "3        Credit  ...  1nSAWAKECC0JEA  1nSAWAKECC0JEA              0   \n",
       "\n",
       "        _dlt_id_2   lon   lat  _dlt_root_id_2 _dlt_parent_id_2  \\\n",
       "0  B/ndNQLSBGpj2g -73.5  40.5  1nSAWAKECC0JEA   1nSAWAKECC0JEA   \n",
       "1  e/7/OvcnJD1uhA -73.5  40.5  1nSAWAKECC0JEA   1nSAWAKECC0JEA   \n",
       "2  B/ndNQLSBGpj2g -73.6  40.6  1nSAWAKECC0JEA   1nSAWAKECC0JEA   \n",
       "3  e/7/OvcnJD1uhA -73.6  40.6  1nSAWAKECC0JEA   1nSAWAKECC0JEA   \n",
       "\n",
       "  _dlt_list_idx_2       _dlt_id_3  \n",
       "0               1  Q5R2dScCRMuxbg  \n",
       "1               1  Q5R2dScCRMuxbg  \n",
       "2               0  YtrudpQY9gWPVw  \n",
       "3               0  YtrudpQY9gWPVw  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To reflect the relationships between parent and child rows, let's join them\n",
    "print(\"\\n\\n\\n joined table\")\n",
    "joined = conn.sql(\n",
    "\"\"\"\n",
    "SELECT r.*, rp.*, rs.*\n",
    "FROM rides AS r\n",
    "LEFT JOIN rides__passengers AS rp \n",
    "  ON r._dlt_id = rp._dlt_parent_id\n",
    "LEFT JOIN rides__stops AS rs \n",
    "  ON r._dlt_id = rs._dlt_parent_id\n",
    "\"\"\"           ).df()\n",
    "\n",
    "display(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Incremental Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that we want to increment the data in the database. We can use the `dlt` library to incrementally load new data into the database. \n",
    "\n",
    "The data represents a ride record, including details about the ride, payment, passengers, and their ratings. Initially, passengers John and Jack had different ratings, but due to a payment issue (\"cancelled\" status in the Payment section), their ratings need to be adjusted. To update the database `write_disposition=\"merge\"` parameter is used to merge the new data with the existing data in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ rides               │\n",
       "│ rides__passengers   │\n",
       "│ rides__stops        │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"vendor_name\": \"VTS\",\n",
    "\t\t\t\t\"record_hash\": \"b00361a396177a9cb410ff61f20015ad\",\n",
    "        \"time\": {\n",
    "            \"pickup\": \"2009-06-14 23:23:00\",\n",
    "            \"dropoff\": \"2009-06-14 23:48:00\"\n",
    "        },\n",
    "        \"Trip_Distance\": 17.52,\n",
    "        \"coordinates\": {\n",
    "            \"start\": {\n",
    "                \"lon\": -73.787442,\n",
    "                \"lat\": 40.641525\n",
    "            },\n",
    "            \"end\": {\n",
    "                \"lon\": -73.980072,\n",
    "                \"lat\": 40.742963\n",
    "            }\n",
    "        },\n",
    "        \"Rate_Code\": None,\n",
    "        \"store_and_forward\": None,\n",
    "        \"Payment\": {\n",
    "            \"type\": \"Credit\",\n",
    "            \"amt\": 20.5,\n",
    "            \"surcharge\": 0,\n",
    "            \"mta_tax\": None,\n",
    "            \"tip\": 9,\n",
    "            \"tolls\": 4.15,\n",
    "\t\t\t\"status\": \"cancelled\" # Status changed from booked to cancelled\n",
    "        },\n",
    "        \"Passenger_Count\": 2,\n",
    "        \"passengers\": [\n",
    "            # Changed rating for jack and john\n",
    "            {\"name\": \"John\", \"rating\": 4.4}, \n",
    "            {\"name\": \"Jack\", \"rating\": 3.6}\n",
    "        ],\n",
    "        \"Stops\": [\n",
    "            {\"lon\": -73.6, \"lat\": 40.6},\n",
    "            {\"lon\": -73.5, \"lat\": 40.5}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "pipeline = dlt.pipeline(destination='duckdb', dataset_name='taxi_rides')\n",
    "\n",
    "\n",
    "info = pipeline.run(    data,\n",
    "                        table_name=\"rides\",\n",
    "                        write_disposition=\"merge\",  # Merge ensures that existing records are updated \n",
    "                        primary_key='record_hash')\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"show tables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Rides table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_hash</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>time__pickup</th>\n",
       "      <th>time__dropoff</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>coordinates__start__lon</th>\n",
       "      <th>coordinates__start__lat</th>\n",
       "      <th>coordinates__end__lon</th>\n",
       "      <th>coordinates__end__lat</th>\n",
       "      <th>payment__type</th>\n",
       "      <th>payment__amt</th>\n",
       "      <th>payment__surcharge</th>\n",
       "      <th>payment__tip</th>\n",
       "      <th>payment__tolls</th>\n",
       "      <th>payment__status</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00361a396177a9cb410ff61f20015ad</td>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-06-14 20:23:00-03:00</td>\n",
       "      <td>2009-06-14 20:48:00-03:00</td>\n",
       "      <td>17.52</td>\n",
       "      <td>-73.787442</td>\n",
       "      <td>40.641525</td>\n",
       "      <td>-73.980072</td>\n",
       "      <td>40.742963</td>\n",
       "      <td>Credit</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.15</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>2</td>\n",
       "      <td>1708189806.507334</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        record_hash vendor_name              time__pickup  \\\n",
       "0  b00361a396177a9cb410ff61f20015ad         VTS 2009-06-14 20:23:00-03:00   \n",
       "\n",
       "              time__dropoff  trip_distance  coordinates__start__lon  \\\n",
       "0 2009-06-14 20:48:00-03:00          17.52               -73.787442   \n",
       "\n",
       "   coordinates__start__lat  coordinates__end__lon  coordinates__end__lat  \\\n",
       "0                40.641525             -73.980072              40.742963   \n",
       "\n",
       "  payment__type  payment__amt  payment__surcharge  payment__tip  \\\n",
       "0        Credit          20.5                   0             9   \n",
       "\n",
       "   payment__tolls payment__status  passenger_count       _dlt_load_id  \\\n",
       "0            4.15       cancelled                2  1708189806.507334   \n",
       "\n",
       "          _dlt_id  \n",
       "0  yTx4L9upBQMLSA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Pasengers table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>_dlt_root_id</th>\n",
       "      <th>_dlt_parent_id</th>\n",
       "      <th>_dlt_list_idx</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>4.4</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>0</td>\n",
       "      <td>4eJubAPCUiHm7g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>3.6</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>1</td>\n",
       "      <td>SjeLUr+iwrKXPw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  rating    _dlt_root_id  _dlt_parent_id  _dlt_list_idx         _dlt_id\n",
       "0  John     4.4  yTx4L9upBQMLSA  yTx4L9upBQMLSA              0  4eJubAPCUiHm7g\n",
       "1  Jack     3.6  yTx4L9upBQMLSA  yTx4L9upBQMLSA              1  SjeLUr+iwrKXPw"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Stops table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>_dlt_root_id</th>\n",
       "      <th>_dlt_parent_id</th>\n",
       "      <th>_dlt_list_idx</th>\n",
       "      <th>_dlt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>0</td>\n",
       "      <td>RCHbdlTVd4pZ6Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>yTx4L9upBQMLSA</td>\n",
       "      <td>1</td>\n",
       "      <td>W/0mx9P9HNHW5w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lon   lat    _dlt_root_id  _dlt_parent_id  _dlt_list_idx         _dlt_id\n",
       "0 -73.6  40.6  yTx4L9upBQMLSA  yTx4L9upBQMLSA              0  RCHbdlTVd4pZ6Q\n",
       "1 -73.5  40.5  yTx4L9upBQMLSA  yTx4L9upBQMLSA              1  W/0mx9P9HNHW5w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\n\\n Rides table:\")\n",
    "rides = conn.sql(\"SELECT * FROM rides\").df()\n",
    "display(rides)\n",
    "\n",
    "print(\"\\n\\n\\n Pasengers table\")\n",
    "passengers = conn.sql(\"SELECT * FROM rides__passengers\").df()\n",
    "display(passengers)\n",
    "print(\"\\n\\n\\n Stops table\")\n",
    "stops = conn.sql(\"SELECT * FROM rides__stops\").df()\n",
    "display(stops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the Merge mode, but dlt currently supports 2 ways of loading incrementally:\n",
    "\n",
    "- Append Mode:\n",
    "\n",
    "    - **Use Case for Immutable Data**: Ideal for loading data where records do not change over time, such as daily taxi rides. Each day's new rides can be appended to the dataset without needing to reload the entire historical data.\n",
    "\n",
    "    - **Slowly Changing Dimension (SCD)**: Useful for tracking changes over time in mutable (stateful) data. By appending versions of the data, we can create an audit trail. For example, tracking changes in a car's color over days; each day's data is loaded, enabling the tracking of any color changes.\n",
    "\n",
    "- Merge Mode:\n",
    "    - **Dynamic Data Updates**: Best suited for data that undergoes changes. This method allows for existing records to be updated based on new information.\n",
    "\n",
    "    - **Example Scenario**: Consider taxi rides with a \"payment status\" field. Initially, a ride may be marked as \"booked\". Later updates might change the status to \"paid\", \"rejected\", or \"cancelled\". Merge mode ensures these updates are accurately reflected in the dataset.\n",
    "\n",
    "The choice of which to use can be summarized in the following diagram:\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/incremental_loading.png\" alt=\"drawing\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following generator to answer questions 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root_generator(limit):\n",
    "    n = 1\n",
    "    while n <= limit:\n",
    "        yield n ** 0.5\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 1**: What is the sum of the outputs of the generator for limit = 5?\n",
    "\n",
    "    - 10.23433234744176\n",
    "    - 7.892332347441762\n",
    "    - **8.382332347441762**\n",
    "    - 9.123332347441762\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sum: 8.382332347441762\n"
     ]
    }
   ],
   "source": [
    "limit = 5\n",
    "total_sum = 0\n",
    "generator = square_root_generator(limit)\n",
    "for sqrt_value in generator:\n",
    "    total_sum += sqrt_value\n",
    "\n",
    "print(\"total sum:\", total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Question 2**: What is the 13th number yielded by the generator?\n",
    "\n",
    "    - 4.236551275463989\n",
    "    - **3.605551275463989**\n",
    "    - 2.345551275463989\n",
    "    - 5.678551275463989\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.4142135623730951\n",
      "1.7320508075688772\n",
      "2.0\n",
      "2.23606797749979\n",
      "2.449489742783178\n",
      "2.6457513110645907\n",
      "2.8284271247461903\n",
      "3.0\n",
      "3.1622776601683795\n",
      "3.3166247903554\n",
      "3.4641016151377544\n",
      "3.605551275463989\n"
     ]
    }
   ],
   "source": [
    "limit = 13\n",
    "generator = square_root_generator(limit)\n",
    "for sqrt_value in generator:\n",
    "    print(sqrt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following generators to answer questions 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_1():\n",
    "    for i in range(1, 6):\n",
    "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 25 + i, \"City\": \"City_A\"}\n",
    "\n",
    "def people_2():\n",
    "    for i in range(3, 9):\n",
    "        yield {\"ID\": i, \"Name\": f\"Person_{i}\", \"Age\": 30 + i, \"City\": \"City_B\", \"Occupation\": f\"Job_{i}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 3**: Append the 2 generators. After correctly appending the data, calculate the sum of all ages of people.\n",
    "\n",
    "    - **353**\n",
    "    - 365\n",
    "    - 378\n",
    "    - 390\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ people              │\n",
       "│ people_2            │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(    destination='duckdb', \n",
    "                            dataset_name='people_dataset' )\n",
    "\n",
    "pipeline.run(   people_1(), \n",
    "                table_name=\"people\", \n",
    "                write_disposition=\"replace\")\n",
    "\n",
    "pipeline.run(   people_2(), \n",
    "                table_name=\"people\", \n",
    "                write_disposition=\"append\")\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"SHOW TABLES\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Person_1</td>\n",
       "      <td>26</td>\n",
       "      <td>City_A</td>\n",
       "      <td>1708195019.1028914</td>\n",
       "      <td>SVCSe9Sv7ddFxw</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Person_2</td>\n",
       "      <td>27</td>\n",
       "      <td>City_A</td>\n",
       "      <td>1708195019.1028914</td>\n",
       "      <td>fx8wMI0m4pIhAg</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name  age    city        _dlt_load_id         _dlt_id occupation\n",
       "0   1  Person_1   26  City_A  1708195019.1028914  SVCSe9Sv7ddFxw       None\n",
       "1   2  Person_2   27  City_A  1708195019.1028914  fx8wMI0m4pIhAg       None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of ages:\n",
      "\n",
      " ┌──────────┐\n",
      "│ sum(Age) │\n",
      "│  int128  │\n",
      "├──────────┤\n",
      "│      353 │\n",
      "└──────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "people = conn.sql(\"SELECT * FROM people\").df()\n",
    "display(people.head(2))\n",
    "\n",
    "sum_ages = conn.sql(\"SELECT SUM(Age) FROM people\")\n",
    "print(\"Sum of ages:\\n\\n\", sum_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Question 4**: Merge the 2 generators using the ID column. Calculate the sum of ages of all the people loaded as described above.\n",
    "\n",
    "    - **215**\n",
    "    - 266\n",
    "    - 241\n",
    "    - 258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since they have overlapping IDs, some of the records from the first load should be replaced by the ones from the second load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ _dlt_loads          │\n",
       "│ _dlt_pipeline_state │\n",
       "│ _dlt_version        │\n",
       "│ people              │\n",
       "│ people_2            │\n",
       "└─────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(    destination='duckdb', \n",
    "                            dataset_name='people_dataset' )\n",
    "\n",
    "pipeline.run(   people_1(), \n",
    "                table_name=\"people_2\", \n",
    "                write_disposition=\"replace\")\n",
    "\n",
    "pipeline.run(   people_2(), \n",
    "                table_name=\"people_2\", \n",
    "                write_disposition=\"merge\")\n",
    "\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "print('Loaded tables: ')\n",
    "display(conn.sql(\"SHOW TABLES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>_dlt_load_id</th>\n",
       "      <th>_dlt_id</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Person_3</td>\n",
       "      <td>33</td>\n",
       "      <td>City_B</td>\n",
       "      <td>1708194986.4371371</td>\n",
       "      <td>qUaDbJnA/CWpfQ</td>\n",
       "      <td>Job_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Person_4</td>\n",
       "      <td>34</td>\n",
       "      <td>City_B</td>\n",
       "      <td>1708194986.4371371</td>\n",
       "      <td>t5THk7Qxmf7W3g</td>\n",
       "      <td>Job_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name  age    city        _dlt_load_id         _dlt_id occupation\n",
       "0   3  Person_3   33  City_B  1708194986.4371371  qUaDbJnA/CWpfQ      Job_3\n",
       "1   4  Person_4   34  City_B  1708194986.4371371  t5THk7Qxmf7W3g      Job_4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of ages:\n",
      "\n",
      " ┌──────────┐\n",
      "│ sum(Age) │\n",
      "│  int128  │\n",
      "├──────────┤\n",
      "│      213 │\n",
      "└──────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people = conn.sql(\"SELECT * FROM people_2\").df()\n",
    "display(people.head(2))\n",
    "\n",
    "sum_ages = conn.sql(\"SELECT SUM(Age) FROM people_2\")\n",
    "print(\"Sum of ages:\\n\\n\", sum_ages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
